{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Scripting and SQL\n",
    "\n",
    "## Python Scripting Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal():\n",
    "    print(f\"The name of this module is: {__name__}\")\n",
    "    # code\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    principal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: newleague.csv\n",
      "File found: wine-ratings-small.csv\n",
      "File found: 01. Data in Python.ipynb\n",
      "File found: sample_data.json\n",
      "File found: 02. Python Scripting and SQL.ipynb\n",
      "File found: main.py\n",
      "File found: wine_names.json\n",
      "File found: other.py\n",
      "File found: wine-ratings.json\n",
      "File found: populate.sql\n",
      "File found: main.py\n",
      "File found: main.cpython-311.pyc\n"
     ]
    }
   ],
   "source": [
    "# The os module is perfect for filesystem operations like \"walking\"\n",
    "# throught directories and files\n",
    "# Although there are many ways of achieving the same effect, a good way\n",
    "# to loop over the filesystem is using `os.walk()`\n",
    "import os\n",
    "for root, directories, files in os.walk('.'):\n",
    "    for _file in files:\n",
    "        print(f\"File found: {_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: ./newleague.csv\n",
      "File found: ./wine-ratings-small.csv\n",
      "File found: ./01. Data in Python.ipynb\n",
      "File found: ./sample_data.json\n",
      "File found: ./02. Python Scripting and SQL.ipynb\n",
      "File found: ./main.py\n",
      "File found: ./wine_names.json\n",
      "File found: ./other.py\n",
      "File found: ./wine-ratings.json\n",
      "File found: ./populate.sql\n",
      "File found: ./examples/main.py\n",
      "File found: ./__pycache__/main.cpython-311.pyc\n"
     ]
    }
   ],
   "source": [
    "# Update the loop so that it shows the absolute path of a file ignoring\n",
    "# directories which we aren't going to track\n",
    "for root, directories, files in os.walk('.'):\n",
    "    for _file in files:\n",
    "        full_path = os.path.join(root, _file)\n",
    "        print(f\"File found: {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 375470b - File: ./newleague.csv\n",
      "Size: 311603b - File: ./wine-ratings-small.csv\n",
      "Size: 84369b - File: ./01. Data in Python.ipynb\n",
      "Size: 2b - File: ./sample_data.json\n",
      "Size: 1410b - File: ./02. Python Scripting and SQL.ipynb\n",
      "Size: 124b - File: ./main.py\n",
      "Size: 31300b - File: ./wine_names.json\n",
      "Size: 61b - File: ./other.py\n",
      "Size: 355744b - File: ./wine-ratings.json\n",
      "Size: 1553b - File: ./populate.sql\n",
      "Size: 536b - File: ./examples/main.py\n",
      "Size: 515b - File: ./__pycache__/main.cpython-311.pyc\n"
     ]
    }
   ],
   "source": [
    "# Update the loop to include the file size\n",
    "for root, directories, files in os.walk('.'):\n",
    "    for _file in files:\n",
    "        full_path = os.path.join(root, _file)\n",
    "        size = os.path.getsize(full_path)\n",
    "        print(f\"Size: {size}b - File: {full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'./newleague.csv': 375470, './wine-ratings-small.csv': 311603, './01. Data in Python.ipynb': 84369, './sample_data.json': 2, './02. Python Scripting and SQL.ipynb': 1410, './main.py': 124, './wine_names.json': 31300, './other.py': 61, './wine-ratings.json': 355744, './populate.sql': 1553, './examples/main.py': 536, './__pycache__/main.cpython-311.pyc': 515}\n"
     ]
    }
   ],
   "source": [
    "# Persist the data into a dictionary. Since file paths are unique you\n",
    "# can use those as dictionary keys\n",
    "file_metadata = {}\n",
    "for root, directories, files in os.walk('.'):\n",
    "    for _file in files:\n",
    "        full_path = os.path.join(root, _file)\n",
    "        size = os.path.getsize(full_path)\n",
    "        file_metadata[full_path] = size\n",
    "print(file_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 375470 Path: ./newleague.csv\n",
      "Size: 355744 Path: ./wine-ratings.json\n",
      "Size: 311603 Path: ./wine-ratings-small.csv\n",
      "Size: 84369 Path: ./01. Data in Python.ipynb\n",
      "Size: 31300 Path: ./wine_names.json\n"
     ]
    }
   ],
   "source": [
    "items_shown = 0\n",
    "    \n",
    "for path, size in sorted(file_metadata.items(), key=lambda x:x[1], reverse=True):\n",
    "    if items_shown > 4:\n",
    "        break\n",
    "    print(f\"Size: {size} Path: {path}\")\n",
    "    items_shown += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to SQlite\n",
    "\n",
    "There are different ways to connect to a SQLite database. For most connections to databases including SQLite you will need a connection object and a cursor. The connection allows you to communicate with the database while the cursor is what executes the query.\n",
    "Start by connecting to an in-memory database first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite can run in-memory, no file will be created, and when the\n",
    "# program ends, the database goes away\n",
    "import sqlite3\n",
    "connection = sqlite3.connect(':memory:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a connection object, and a running database that lives in-memory while this program runs. The next step is to create some tables for the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the query to create a table to hold file paths and sizes\n",
    "# in bytes for those files\n",
    "table = 'CREATE TABLE files (id integer primary key, path TEXT, bytes INTEGER)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two steps for executing the query. First we use the cursor to execute it, and then we commit the result to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table files already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cursor \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcursor()\n\u001b[0;32m----> 2\u001b[0m cursor\u001b[39m.\u001b[39;49mexecute(table)\n\u001b[1;32m      3\u001b[0m connection\u001b[39m.\u001b[39mcommit()\n",
      "\u001b[0;31mOperationalError\u001b[0m: table files already exists"
     ]
    }
   ],
   "source": [
    "cursor = connection.cursor()\n",
    "cursor.execute(table)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding data \n",
    "Now add a single entry into the database. The steps are to execute the query with the cursor and then commit with the `connection` object.\n",
    "\n",
    "**Exercise:** Try adding more entries to the database, ensure that there aren't any errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('INSERT INTO files (path, bytes) VALUES(\"/home/user/.zshrc\", 100)')\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query the database with a minimal instruction to check if the addition was succesful. The query is done with the cursor, just like before. And the resulting object that the cursor returns is an iterable that you can use to loop over the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '/home/user/.zshrc', 100)\n"
     ]
    }
   ],
   "source": [
    "result = cursor.execute('SELECT * from files')\n",
    "for line in result:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Querying from a SQLite Database in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Sara', 'Christian'],\n",
       " ['Edwin', 'Fox'],\n",
       " ['James', 'Nelson'],\n",
       " ['Christopher', 'Garcia'],\n",
       " ['Richard', 'Chen'],\n",
       " ['Jordan', 'West'],\n",
       " ['Jeremy', 'Clayton'],\n",
       " ['Emily', 'Baxter'],\n",
       " ['Matthew', 'Bishop'],\n",
       " ['Scott', 'Garcia'],\n",
       " ['Jocelyn', 'Arnold'],\n",
       " ['Terry', 'Hughes'],\n",
       " ['Jeffrey', 'Lee'],\n",
       " ['John', 'Reynolds'],\n",
       " ['Jessica', 'Armstrong'],\n",
       " ['Pamela', 'Campos'],\n",
       " ['Stacie', 'Merritt'],\n",
       " ['Tammy', 'Walker'],\n",
       " ['Calvin', 'Richards'],\n",
       " ['Ashley', 'Dean'],\n",
       " ['Thomas', 'Nguyen'],\n",
       " ['Ryan', 'Meyers'],\n",
       " ['Jessica', 'Thornton'],\n",
       " ['Kelli', 'Baker'],\n",
       " ['Lindsay', 'Brooks'],\n",
       " ['Cynthia', 'Patterson'],\n",
       " ['Ronald', 'Allen'],\n",
       " ['Anthony', 'Ferguson'],\n",
       " ['Anna', 'Myers'],\n",
       " ['David', 'Meyers'],\n",
       " ['Richard', 'Warren'],\n",
       " ['Mary', 'Sims'],\n",
       " ['Joshua', 'Scott'],\n",
       " ['Stephanie', 'Walls'],\n",
       " ['Lauren', 'Keller'],\n",
       " ['Samuel', 'Rivas'],\n",
       " ['Kara', 'Harris'],\n",
       " ['Susan', 'Foster'],\n",
       " ['Jordan', 'Bradley'],\n",
       " ['Erica', 'Pratt'],\n",
       " ['Kenneth', 'Hopkins'],\n",
       " ['Richard', 'Dunn'],\n",
       " ['Eric', 'Smith'],\n",
       " ['Tammy', 'Mcdonald'],\n",
       " ['Jacob', 'Meza'],\n",
       " ['Robin', 'Gilmore'],\n",
       " ['Kimberly', 'Watson'],\n",
       " ['Joshua', 'Lindsey'],\n",
       " ['Jason', 'Campbell'],\n",
       " ['Robert', 'Alvarez'],\n",
       " ['Elizabeth', 'Patel'],\n",
       " ['Jonathan', 'Butler'],\n",
       " ['Tracy', 'Hernandez'],\n",
       " ['Dillon', 'Wells'],\n",
       " ['Dylan', 'Phillips'],\n",
       " ['Norma', 'Noble'],\n",
       " ['Carrie', 'Reyes'],\n",
       " ['Laura', 'Blair'],\n",
       " ['Michael', 'Vargas'],\n",
       " ['Justin', 'Lindsey'],\n",
       " ['Shane', 'Rodriguez'],\n",
       " ['Andrew', 'Roberts'],\n",
       " ['Jason', 'Dawson'],\n",
       " ['Brian', 'Snyder'],\n",
       " ['Christopher', 'Franklin'],\n",
       " ['Nicholas', 'Ward'],\n",
       " ['James', 'Berry'],\n",
       " ['Ashley', 'Welch'],\n",
       " ['Jeremy', 'Spence'],\n",
       " ['Brandon', 'Blackburn'],\n",
       " ['Jaime', 'Martin'],\n",
       " ['Paige', 'Weiss'],\n",
       " ['Julie', 'Clarke'],\n",
       " ['Leah', 'Little'],\n",
       " ['Samantha', 'Herman'],\n",
       " ['James', 'Walters'],\n",
       " ['John', 'Hunt'],\n",
       " ['Kenneth', 'Mcmillan'],\n",
       " ['Tracy', 'Powers'],\n",
       " ['Melissa', 'Young'],\n",
       " ['Kenneth', 'Marshall'],\n",
       " ['Daniel', 'David'],\n",
       " ['Andrea', 'Long'],\n",
       " ['Nicholas', 'Curry'],\n",
       " ['Jesse', 'Medina'],\n",
       " ['Gabriella', 'Ramirez'],\n",
       " ['Teresa', 'Knight'],\n",
       " ['Sarah', 'Todd'],\n",
       " ['Ralph', 'Hill'],\n",
       " ['Melissa', 'Mathis'],\n",
       " ['Antonio', 'Trujillo'],\n",
       " ['Catherine', 'Weber'],\n",
       " ['Nathaniel', 'Short'],\n",
       " ['Nicholas', 'Soto'],\n",
       " ['Brandon', 'Robertson']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()\n",
    "names = [fake.name().split() for i in range(100)]\n",
    "names = [name for name in names if len(name) == 2]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "connection = sqlite3.connect('sample.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query = 'INSERT INTO people(name, surname) VALUES(?, ?)'\n",
    "cursor = connection.cursor()\n",
    "for name in names:\n",
    "    cursor.execute(insert_query, name)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Sara', 'Christian')\n",
      "(2, 'Edwin', 'Fox')\n",
      "(3, 'James', 'Nelson')\n",
      "(4, 'Christopher', 'Garcia')\n",
      "(5, 'Richard', 'Chen')\n",
      "(6, 'Jordan', 'West')\n",
      "(7, 'Jeremy', 'Clayton')\n",
      "(8, 'Emily', 'Baxter')\n",
      "(9, 'Matthew', 'Bishop')\n",
      "(10, 'Scott', 'Garcia')\n"
     ]
    }
   ],
   "source": [
    "select_query = 'SELECT * from people LIMIT 10'\n",
    "for i in cursor.execute(select_query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Databases with SQL\n",
    "\n",
    "We've already seen a couple of SQL queries when creating a database table and checking if data was present. Now we will go beyond those basics queries to do slightly more advanced queries, like searching and filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with an in-memory SQLite database again\n",
    "import sqlite3\n",
    "connection = sqlite3.connect(':memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table again for holding a path and size, just like before\n",
    "table = 'CREATE TABLE files (id integer primary key, path TEXT, bytes INTEGER)'\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(table)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a `large_files.py` file that has a `files` variable which holds a list of tuples with some sample data we can use to populate the database. Import that module and use the list to iterate over it and then populate the database\n",
    "\n",
    "In this section you will use a special SQL syntax in SQLite to insert values from Python into the SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_files import files\n",
    "\n",
    "for metadata in files:\n",
    "    query = 'INSERT INTO files(path, bytes) VALUES(?, ?)'\n",
    "    # the execute() method accepts a query and optionally a tuple with values \n",
    "    # corresponding to the question marks in VALUES\n",
    "    cursor.execute(query, metadata)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've seen `CREATE` and `INSERT`. Let's try a new SQL statement to make a selection. The `SELECT` statement produces a result from one or more tables and from one or many rows. \n",
    "\n",
    "Note the particular (and strict) order of SQL statements:\n",
    "\n",
    "- `SELECT`\n",
    "- `FROM`\n",
    "- `WHERE`\n",
    "- `GROUP BY`\n",
    "- `HAVING`\n",
    "- `ORDER BY`\n",
    "\n",
    "Since SQLite returns an iterator as a result always, then it is required to loop over the resulting object. Create a query to count the items in the `files` table. This query will use the `COUNT()` function that produces a number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT COUNT(id) from files'\n",
    "\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting distinct row data\n",
    "Counting items is a good way of checking the amount of items that exist in the database. Without using `COUNT(id)` the previous query would've produced two thousand entries. Use the `LIMIT` statement to set the maximum number of entries that can be produced, then remove the `COUNT(id)` function and use `*` instead to use all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * from files LIMIT(10)'\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `*` means every row in the table. The table in this case is `files`. The next query specifies using the `id` row only. \n",
    "\n",
    "**Exercise:** Update the cell contents so that it shows paths instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT id FROM files LIMIT(10)'\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next query uses ID and Bytes. Update the query once again to select two rows in the table: `bytes` and `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT id,bytes FROM files LIMIT(10)'\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting distinct data\n",
    "You now know how to extract data from certain rows and how to limit that data. Next, we'll use more SQL statements to further find and filter out results so that you can get specific results.\n",
    "\n",
    "**Exercise:** Use the next query to find 10 files that are bigger than 1mb (1000000 bytes) using a new statement (`WHERE`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT path FROM files WHERE bytes>1000000 LIMIT(10)'\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query shows the paths but not the sizes. \n",
    "\n",
    "**Exercise:** Try updating the previous query to show both the path and the size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ''\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL has many helper functions, in this case the next query uses `MAX()` which can find the highest value in a column. Do you think that `LIMIT(10)` makes sense in this query? Why? What happens if you remove the `LIMIT(10)` clause?\n",
    "\n",
    "**Exercise:** Remote the `LIMIT()` clause and check your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT path,MAX(bytes) FROM files LIMIT(10)'\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL queries can be compounded for more conditionals. In Python, you can make the query more readable by using triple quotes and adding the queries in a multi-line variable.\n",
    "\n",
    "**Exercise:** Use other conditions to match different sizes and limit to a different number of entries returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT path,bytes FROM files \n",
    "    WHERE bytes>3000000 \n",
    "    AND bytes<4400000 LIMIT(100)\n",
    "\"\"\"\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching\n",
    "Sometimes you can't tell exactly what is it that you are looking for in a query. SQL allows for matching patterns. In the file paths situation, you might know that a specific file ends with `.zip` but you don't know where it is. \n",
    "\n",
    "**Exercise:** Use the `LIKE` operator to match and find a cache file related to an Address Book application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT path,bytes FROM files \n",
    "    WHERE path LIKE '%AddressBook%'\n",
    "\"\"\"\n",
    "for i in cursor.execute(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `%` means to match any text of zero or more characters. So `%AddressBook%` is very lenient for anything before it and after it. Try adding a condition that filters the result by size. Anything over 2MB (or 2000000 bytes) and see if you can reduce the amount of output.\n",
    "\n",
    "There are other variations for search like using an underscore (`_`). That means any single character. If you know that a file prefix or suffix is, you could use this to fine-tune your search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
